{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions on how to prepare the model used in the following publication:\n",
    "B. Pickering, R. Choudhary. Mitigating risk in district-level energy investment decisions by scenario optimisation, In: Proceedings of the 4th IBPSA-England Conference BSO 2018, Emmanuel College, Cambridge, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant packages\n",
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import calliope\n",
    "from calliope.core import time\n",
    "\n",
    "## internal package which includes functions for scenario reduction\n",
    "import utils\n",
    "\n",
    "os.chdir('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the mean model, to have a model to which we can manually apply clustering\n",
    "mean_model = calliope.Model('model.yaml')\n",
    "\n",
    "## Get user-defined clusters (monthly weekday/weekend)\n",
    "clusters = pd.read_csv(os.path.join('timeseries_data', 'BSO2018', 'clusters.csv'), \n",
    "                       header=None, index_col=0, parse_dates=True)[1]\n",
    "\n",
    "## Update timeseries to fit clusters\n",
    "timeseries_data = mean_model._model_data.copy()\n",
    "timeseries_data = timeseries_data.drop([\n",
    "    i for i in timeseries_data.variables\n",
    "    if 'timesteps' not in timeseries_data[i].dims or 'timestep_' in i\n",
    "])\n",
    "\n",
    "for dim in timeseries_data.dims:\n",
    "    timeseries_data[dim] = mean_model._model_data[dim]\n",
    "    \n",
    "timeseries_data.attrs['_daily_timesteps'] = [\n",
    "    mean_model._model_data.timestep_resolution.loc[i].values\n",
    "    for i in np.unique(mean_model._model_data.timesteps.to_index().strftime('%Y-%m-%d'))\n",
    "][0]\n",
    "new_model_data = time.clustering.map_clusters_to_data(timeseries_data, clusters, how='mean')\n",
    "for v in new_model_data.data_vars.values():\n",
    "    v.attrs['is_result'] = 0\n",
    "new_model_data = time.funcs._copy_non_t_vars(mean_model._model_data, new_model_data)\n",
    "data_coords = mean_model._model_data.copy().coords\n",
    "del data_coords['timesteps']\n",
    "new_model_data.update(data_coords)\n",
    "\n",
    "mean_model._model_data = new_model_data\n",
    "mean_model.inputs = mean_model._model_data.filter_by_attrs(is_result=0)\n",
    "## Save to netcdf if desired, to avoid running this step again\n",
    "# mean_model.to_netcdf('mean_model_clustered_timeseries.nc') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a scenario, e.g. scenario 1, into the model\n",
    "\n",
    "def get_scenario_model(scenario):\n",
    "    scenario_demand = pd.DataFrame(index=mean_model.inputs.timesteps)\n",
    "    for energy in ['cooling', 'electricity', 'UPS']:\n",
    "        ## get scenario demand from compressed CSV (gzip compression applied to reduce repository size)\n",
    "        _demand = pd.read_csv(\n",
    "            os.path.join('timeseries_data', 'scenarios', 'demand_{}_{}.csv.gz'.format(energy, scenario)),\n",
    "            header=0, index_col=0, parse_dates=True\n",
    "        )\n",
    "        ## location -> loc::tech terminology, as used in Calliope\n",
    "        _demand.rename(columns={i: '{}::demand_{}'.format(i, energy) for i in _demand.columns}, inplace=True)\n",
    "        scenario_demand = scenario_demand.join(_demand)\n",
    "    index_slice = {'loc_techs_finite_resource': scenario_demand.columns, 'timesteps': scenario_demand.index.values}\n",
    "\n",
    "    ## Update relevant demand data in the model. We create a new Calliope model here, so the mean model remains intact\n",
    "    scenario_model = calliope.Model(config=None, model_data=mean_model._model_data.copy(deep=True))\n",
    "    scenario_model._model_data.resource.loc[index_slice] = scenario_demand.T.values\n",
    "\n",
    "    return scenario_model\n",
    "\n",
    "scenario_model = get_scenario_model(scenario=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To undertake scenario reduction, run all scenarios independently, then load them into one xarray Dataset:\n",
    "all_scenarios = xr.concat(\n",
    "    [xr.open_dataset('path_to_scenario_model_{}'.format(i)) for i in range(1, 501)], \n",
    "    dim=pd.Index(data=[i for i in range(1, 501)], name='scenarios'),\n",
    "    data_vars='different'\n",
    ")\n",
    "\n",
    "## Then run scenario reduction\n",
    "reduced_scenarios = utils.get_reduced_scenarios(all_scenarios.cost.values, 16)\n",
    "reduced_scenarios_df = utils.get_redistributed_probabilities(all_scenarios.cost.values, reduced_scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create multi-scenario model, for scenario optimisation\n",
    "scenarios = pd.read_csv(os.path.join('timeseries_data', 'reduced_scenarios.csv'), header=0, index_col=0)\n",
    "scenario_model = calliope.Model(\n",
    "    config=None, \n",
    "    model_data=xr.concat(\n",
    "        [get_scenario_model(int(i))._model_data for i in scenarios.reduced_scenario.unique()], \n",
    "        dim=pd.Index(data=scenarios.reduced_scenario.astype(int).unique(), name='scenarios'), data_vars='different'\n",
    "    )\n",
    ")\n",
    "\n",
    "## Add scenario probability\n",
    "scenario_model._model_data['probability'] = xr.DataArray.from_dict({\n",
    "    'data': scenarios.loc[scenario_model._model_data.scenarios.values, 'probability'].values,\n",
    "    'dims': ('scenarios')\n",
    "})\n",
    "scenario_model._model_data['probability'].attrs['is_result'] = 0\n",
    "\n",
    "## Add SO-related attributes\n",
    "SO_attrs = {\n",
    "    'run.mode': 'robust_plan',\n",
    "    'run.beta': 5,\n",
    "    'run.alpha': 0.9,\n",
    "    'run.objective': 'robust_optimal_cost_minimization'\n",
    "}\n",
    "scenario_model._model_data.attrs.update(SO_attrs)\n",
    "\n",
    "## Edit solver, if necessary\n",
    "# scenario_model._model_data.attrs['run.solver'] = ''\n",
    "\n",
    "## Recommended to save this to file, for running on a remote cluster:\n",
    "# scenario_model.to_netcdf('scenario_model.nc')\n",
    "\n",
    "## If you want to run right here:\n",
    "# scenario_model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unmet demand test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update bigM used for unmet demand\n",
    "scenario_model._model_data.attrs['run.bigM'] = 1e3 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:calliope]",
   "language": "python",
   "name": "conda-env-calliope-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
